{"ast":null,"code":"/**\r\n * Copyright (c) 2017 mol* contributors, licensed under MIT, See LICENSE file for more info.\r\n *\r\n * mostly from https://github.com/dsehnal/CIFTools.js\r\n * @author David Sehnal <david.sehnal@gmail.com>\r\n * @author Alexander Rose <alexander.rose@weirdbyte.de>\r\n */\nimport { __awaiter, __generator } from \"tslib\";\nimport { chunkedSubtask } from '../../../../mol-task';\nexport { Tokenizer };\n\nfunction Tokenizer(data) {\n  return {\n    data: data,\n    position: 0,\n    length: data.length,\n    lineNumber: 1,\n    tokenStart: 0,\n    tokenEnd: 0\n  };\n}\n\n(function (Tokenizer) {\n  function getTokenString(state) {\n    return state.data.substring(state.tokenStart, state.tokenEnd);\n  }\n\n  Tokenizer.getTokenString = getTokenString;\n  /** Resets the state */\n\n  function reset(state) {\n    state.position = 0;\n    state.lineNumber = 1;\n    state.tokenStart = 0;\n    state.tokenEnd = 0;\n  }\n\n  Tokenizer.reset = reset;\n  /**\r\n   * Eat everything until a newline occurs.\r\n   */\n\n  function eatLine(state) {\n    var data = state.data;\n\n    while (state.position < state.length) {\n      switch (data.charCodeAt(state.position)) {\n        case 10:\n          // \\n\n          state.tokenEnd = state.position;\n          ++state.position;\n          ++state.lineNumber;\n          return true;\n\n        case 13:\n          // \\r\n          state.tokenEnd = state.position;\n          ++state.position;\n          ++state.lineNumber;\n\n          if (data.charCodeAt(state.position) === 10) {\n            ++state.position;\n          }\n\n          return true;\n\n        default:\n          ++state.position;\n          break;\n      }\n    }\n\n    state.tokenEnd = state.position;\n    return state.tokenStart !== state.tokenEnd;\n  }\n\n  Tokenizer.eatLine = eatLine;\n  /** Sets the current token start to the current position */\n\n  function markStart(state) {\n    state.tokenStart = state.position;\n  }\n\n  Tokenizer.markStart = markStart;\n  /** Sets the current token start to current position and moves to the next line. */\n\n  function markLine(state) {\n    state.tokenStart = state.position;\n    return eatLine(state);\n  }\n\n  Tokenizer.markLine = markLine;\n  /** Advance the state and return line as string. */\n\n  function readLine(state) {\n    markLine(state);\n    return getTokenString(state);\n  }\n\n  Tokenizer.readLine = readLine;\n  /** Advance the state and return trimmed line as string. */\n\n  function readLineTrim(state) {\n    markLine(state);\n    var position = state.position;\n    trim(state, state.tokenStart, state.tokenEnd);\n    state.position = position;\n    return getTokenString(state);\n  }\n\n  Tokenizer.readLineTrim = readLineTrim;\n\n  function readLinesChunk(state, count, tokens) {\n    var read = 0;\n\n    for (var i = 0; i < count; i++) {\n      if (!markLine(state)) return read;\n      TokenBuilder.addUnchecked(tokens, state.tokenStart, state.tokenEnd);\n      read++;\n    }\n\n    return read;\n  }\n  /** Advance the state by the given number of lines and return them*/\n\n\n  function markLines(state, count) {\n    var lineTokens = TokenBuilder.create(state.data, count * 2);\n    readLinesChunk(state, count, lineTokens);\n    return lineTokens;\n  }\n\n  Tokenizer.markLines = markLines;\n  /** Advance the state by the given number of lines and return them */\n\n  function readLines(state, count) {\n    var ret = [];\n\n    for (var i = 0; i < count; i++) {\n      ret.push(Tokenizer.readLine(state));\n    }\n\n    return ret;\n  }\n\n  Tokenizer.readLines = readLines;\n  /** Advance the state by the given number of lines and return line starts/ends as tokens. */\n\n  function readLinesAsync(state, count, ctx, initialLineCount) {\n    if (initialLineCount === void 0) {\n      initialLineCount = 100000;\n    }\n\n    return __awaiter(this, void 0, void 0, function () {\n      var length, lineTokens, linesAlreadyRead;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            length = state.length;\n            lineTokens = TokenBuilder.create(state.data, count * 2);\n            linesAlreadyRead = 0;\n            return [4\n            /*yield*/\n            , chunkedSubtask(ctx, initialLineCount, state, function (chunkSize, state) {\n              var linesToRead = Math.min(count - linesAlreadyRead, chunkSize);\n              readLinesChunk(state, linesToRead, lineTokens);\n              linesAlreadyRead += linesToRead;\n              return linesToRead;\n            }, function (ctx, state) {\n              return ctx.update({\n                message: 'Parsing...',\n                current: state.position,\n                max: length\n              });\n            })];\n\n          case 1:\n            _a.sent();\n\n            return [2\n            /*return*/\n            , lineTokens];\n        }\n      });\n    });\n  }\n\n  Tokenizer.readLinesAsync = readLinesAsync;\n\n  function readAllLines(data) {\n    var state = Tokenizer(data);\n    var tokens = TokenBuilder.create(state.data, Math.max(data.length / 80, 2));\n\n    while (markLine(state)) {\n      TokenBuilder.add(tokens, state.tokenStart, state.tokenEnd);\n    }\n\n    return tokens;\n  }\n\n  Tokenizer.readAllLines = readAllLines;\n\n  function readLinesChunkChecked(state, count, tokens) {\n    var read = 0;\n\n    for (var i = 0; i < count; i++) {\n      if (!markLine(state)) return read;\n      TokenBuilder.add(tokens, state.tokenStart, state.tokenEnd);\n      read++;\n    }\n\n    return read;\n  }\n\n  function readAllLinesAsync(data, ctx, chunkSize) {\n    if (chunkSize === void 0) {\n      chunkSize = 100000;\n    }\n\n    return __awaiter(this, void 0, void 0, function () {\n      var state, tokens;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            state = Tokenizer(data);\n            tokens = TokenBuilder.create(state.data, Math.max(data.length / 80, 2));\n            return [4\n            /*yield*/\n            , chunkedSubtask(ctx, chunkSize, state, function (chunkSize, state) {\n              readLinesChunkChecked(state, chunkSize, tokens);\n              return state.position < state.length ? chunkSize : 0;\n            }, function (ctx, state) {\n              return ctx.update({\n                message: 'Parsing...',\n                current: state.position,\n                max: length\n              });\n            })];\n\n          case 1:\n            _a.sent();\n\n            return [2\n            /*return*/\n            , tokens];\n        }\n      });\n    });\n  }\n\n  Tokenizer.readAllLinesAsync = readAllLinesAsync;\n  /**\r\n   * Eat everything until a whitespace/newline occurs.\r\n   */\n\n  function eatValue(state) {\n    while (state.position < state.length) {\n      switch (state.data.charCodeAt(state.position)) {\n        case 9: // \\t\n\n        case 10: // \\n\n\n        case 13: // \\r\n\n        case 32:\n          // ' '\n          state.tokenEnd = state.position;\n          return;\n\n        default:\n          ++state.position;\n          break;\n      }\n    }\n\n    state.tokenEnd = state.position;\n  }\n\n  Tokenizer.eatValue = eatValue;\n  /**\r\n   * Skips all the whitespace - space, tab, newline, CR\r\n   * Handles incrementing line count.\r\n   */\n\n  function skipWhitespace(state) {\n    var prev = -1;\n\n    while (state.position < state.length) {\n      var c = state.data.charCodeAt(state.position);\n\n      switch (c) {\n        case 9: // '\\t'\n\n        case 32:\n          // ' '\n          prev = c;\n          ++state.position;\n          break;\n\n        case 10:\n          // \\n\n          // handle \\r\\n\n          if (prev !== 13) {\n            ++state.lineNumber;\n          }\n\n          prev = c;\n          ++state.position;\n          break;\n\n        case 13:\n          // \\r\n          prev = c;\n          ++state.position;\n          ++state.lineNumber;\n          break;\n\n        default:\n          return prev;\n      }\n    }\n\n    return prev;\n  }\n\n  Tokenizer.skipWhitespace = skipWhitespace;\n  /** Trims spaces and tabs */\n\n  function trim(state, start, end) {\n    var data = state.data;\n    var s = start,\n        e = end - 1;\n    var c = data.charCodeAt(s);\n\n    while ((c === 9 || c === 32) && s <= e) c = data.charCodeAt(++s);\n\n    c = data.charCodeAt(e);\n\n    while ((c === 9 || c === 32) && e >= s) c = data.charCodeAt(--e);\n\n    state.tokenStart = s;\n    state.tokenEnd = e + 1;\n    state.position = end;\n    return state;\n  }\n\n  Tokenizer.trim = trim;\n})(Tokenizer || (Tokenizer = {}));\n\nexport function trimStr(data, start, end) {\n  var s = start,\n      e = end - 1;\n  var c = data.charCodeAt(s);\n\n  while ((c === 9 || c === 32) && s <= e) c = data.charCodeAt(++s);\n\n  c = data.charCodeAt(e);\n\n  while ((c === 9 || c === 32) && e >= s) c = data.charCodeAt(--e);\n\n  return data.substring(s, e + 1);\n}\nexport var TokenBuilder;\n\n(function (TokenBuilder) {\n  function resize(builder) {\n    // scale the size using golden ratio, because why not.\n    var newBuffer = new Uint32Array(1.61 * builder.indices.length | 0);\n    newBuffer.set(builder.indices);\n    builder.indices = newBuffer;\n    builder.indicesLenMinus2 = newBuffer.length - 2 | 0;\n  }\n\n  function add(tokens, start, end) {\n    var builder = tokens;\n\n    if (builder.offset > builder.indicesLenMinus2) {\n      resize(builder);\n    }\n\n    builder.indices[builder.offset++] = start;\n    builder.indices[builder.offset++] = end;\n    tokens.count++;\n  }\n\n  TokenBuilder.add = add;\n\n  function addToken(tokens, tokenizer) {\n    add(tokens, tokenizer.tokenStart, tokenizer.tokenEnd);\n  }\n\n  TokenBuilder.addToken = addToken;\n\n  function addUnchecked(tokens, start, end) {\n    tokens.indices[tokens.offset++] = start;\n    tokens.indices[tokens.offset++] = end;\n    tokens.count++;\n  }\n\n  TokenBuilder.addUnchecked = addUnchecked;\n\n  function create(data, size) {\n    size = Math.max(10, size);\n    return {\n      data: data,\n      indicesLenMinus2: size - 2 | 0,\n      count: 0,\n      offset: 0,\n      indices: new Uint32Array(size)\n    };\n  }\n\n  TokenBuilder.create = create;\n})(TokenBuilder || (TokenBuilder = {}));","map":{"version":3,"sources":["../../../../../src/mol-io/reader/common/text/tokenizer.ts"],"names":[],"mappings":"AAAA;;;;;;AAMG;;AAEH,SAAS,cAAT,QAA+C,sBAA/C;AAEA,SAAS,SAAT;;AAmBA,SAAS,SAAT,CAAmB,IAAnB,EAA+B;AAC3B,SAAO;AACH,IAAA,IAAI,EAAA,IADD;AAEH,IAAA,QAAQ,EAAE,CAFP;AAGH,IAAA,MAAM,EAAE,IAAI,CAAC,MAHV;AAIH,IAAA,UAAU,EAAE,CAJT;AAKH,IAAA,UAAU,EAAE,CALT;AAMH,IAAA,QAAQ,EAAE;AANP,GAAP;AAQH;;AAED,CAAA,UAAU,SAAV,EAAmB;AACf,WAAgB,cAAhB,CAA+B,KAA/B,EAA+C;AAC3C,WAAO,KAAK,CAAC,IAAN,CAAW,SAAX,CAAqB,KAAK,CAAC,UAA3B,EAAuC,KAAK,CAAC,QAA7C,CAAP;AACH;;AAFe,EAAA,SAAA,CAAA,cAAA,GAAc,cAAd;AAIhB;;AACA,WAAgB,KAAhB,CAAsB,KAAtB,EAAsC;AAClC,IAAA,KAAK,CAAC,QAAN,GAAiB,CAAjB;AACA,IAAA,KAAK,CAAC,UAAN,GAAmB,CAAnB;AACA,IAAA,KAAK,CAAC,UAAN,GAAmB,CAAnB;AACA,IAAA,KAAK,CAAC,QAAN,GAAiB,CAAjB;AACH;;AALe,EAAA,SAAA,CAAA,KAAA,GAAK,KAAL;AAOhB;;AAEG;;AACH,WAAgB,OAAhB,CAAwB,KAAxB,EAAwC;AAC5B,QAAA,IAAI,GAAK,KAAK,CAAV,IAAJ;;AACR,WAAO,KAAK,CAAC,QAAN,GAAiB,KAAK,CAAC,MAA9B,EAAsC;AAClC,cAAQ,IAAI,CAAC,UAAL,CAAgB,KAAK,CAAC,QAAtB,CAAR;AACI,aAAK,EAAL;AAAS;AACL,UAAA,KAAK,CAAC,QAAN,GAAiB,KAAK,CAAC,QAAvB;AACA,YAAE,KAAK,CAAC,QAAR;AACA,YAAE,KAAK,CAAC,UAAR;AACA,iBAAO,IAAP;;AACJ,aAAK,EAAL;AAAS;AACL,UAAA,KAAK,CAAC,QAAN,GAAiB,KAAK,CAAC,QAAvB;AACA,YAAE,KAAK,CAAC,QAAR;AACA,YAAE,KAAK,CAAC,UAAR;;AACA,cAAI,IAAI,CAAC,UAAL,CAAgB,KAAK,CAAC,QAAtB,MAAoC,EAAxC,EAA4C;AACxC,cAAE,KAAK,CAAC,QAAR;AACH;;AACD,iBAAO,IAAP;;AACJ;AACI,YAAE,KAAK,CAAC,QAAR;AACA;AAhBR;AAkBH;;AACD,IAAA,KAAK,CAAC,QAAN,GAAiB,KAAK,CAAC,QAAvB;AACA,WAAO,KAAK,CAAC,UAAN,KAAqB,KAAK,CAAC,QAAlC;AACH;;AAxBe,EAAA,SAAA,CAAA,OAAA,GAAO,OAAP;AA0BhB;;AACA,WAAgB,SAAhB,CAA0B,KAA1B,EAA0C;AACtC,IAAA,KAAK,CAAC,UAAN,GAAmB,KAAK,CAAC,QAAzB;AACH;;AAFe,EAAA,SAAA,CAAA,SAAA,GAAS,SAAT;AAIhB;;AACA,WAAgB,QAAhB,CAAyB,KAAzB,EAAyC;AACrC,IAAA,KAAK,CAAC,UAAN,GAAmB,KAAK,CAAC,QAAzB;AACA,WAAO,OAAO,CAAC,KAAD,CAAd;AACH;;AAHe,EAAA,SAAA,CAAA,QAAA,GAAQ,QAAR;AAKhB;;AACA,WAAgB,QAAhB,CAAyB,KAAzB,EAAyC;AACrC,IAAA,QAAQ,CAAC,KAAD,CAAR;AACA,WAAO,cAAc,CAAC,KAAD,CAArB;AACH;;AAHe,EAAA,SAAA,CAAA,QAAA,GAAQ,QAAR;AAKhB;;AACA,WAAgB,YAAhB,CAA6B,KAA7B,EAA6C;AACzC,IAAA,QAAQ,CAAC,KAAD,CAAR;AACA,QAAM,QAAQ,GAAG,KAAK,CAAC,QAAvB;AACA,IAAA,IAAI,CAAC,KAAD,EAAQ,KAAK,CAAC,UAAd,EAA0B,KAAK,CAAC,QAAhC,CAAJ;AACA,IAAA,KAAK,CAAC,QAAN,GAAiB,QAAjB;AACA,WAAO,cAAc,CAAC,KAAD,CAArB;AACH;;AANe,EAAA,SAAA,CAAA,YAAA,GAAY,YAAZ;;AAQhB,WAAS,cAAT,CAAwB,KAAxB,EAA0C,KAA1C,EAAyD,MAAzD,EAAuE;AACnE,QAAI,IAAI,GAAG,CAAX;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAApB,EAA2B,CAAC,EAA5B,EAAgC;AAC5B,UAAI,CAAC,QAAQ,CAAC,KAAD,CAAb,EAAsB,OAAO,IAAP;AACtB,MAAA,YAAY,CAAC,YAAb,CAA0B,MAA1B,EAAkC,KAAK,CAAC,UAAxC,EAAoD,KAAK,CAAC,QAA1D;AACA,MAAA,IAAI;AACP;;AACD,WAAO,IAAP;AACH;AAED;;;AACA,WAAgB,SAAhB,CAA0B,KAA1B,EAA4C,KAA5C,EAAyD;AACrD,QAAM,UAAU,GAAG,YAAY,CAAC,MAAb,CAAoB,KAAK,CAAC,IAA1B,EAAgC,KAAK,GAAG,CAAxC,CAAnB;AACA,IAAA,cAAc,CAAC,KAAD,EAAQ,KAAR,EAAe,UAAf,CAAd;AACA,WAAO,UAAP;AACH;;AAJe,EAAA,SAAA,CAAA,SAAA,GAAS,SAAT;AAMhB;;AACA,WAAgB,SAAhB,CAA0B,KAA1B,EAA4C,KAA5C,EAAyD;AACrD,QAAM,GAAG,GAAa,EAAtB;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAApB,EAA2B,CAAC,EAA5B,EAAgC;AAC5B,MAAA,GAAG,CAAC,IAAJ,CAAS,SAAS,CAAC,QAAV,CAAmB,KAAnB,CAAT;AACH;;AACD,WAAO,GAAP;AACH;;AANe,EAAA,SAAA,CAAA,SAAA,GAAS,SAAT;AAQhB;;AACA,WAAsB,cAAtB,CAAqC,KAArC,EAAuD,KAAvD,EAAsE,GAAtE,EAA2F,gBAA3F,EAAoH;AAAzB,QAAA,gBAAA,KAAA,KAAA,CAAA,EAAA;AAAA,MAAA,gBAAA,GAAA,MAAA;AAAyB;;;;;;;AACxG,YAAA,MAAM,GAAK,KAAK,CAAV,MAAN;AACF,YAAA,UAAU,GAAG,YAAY,CAAC,MAAb,CAAoB,KAAK,CAAC,IAA1B,EAAgC,KAAK,GAAG,CAAxC,CAAb;AAEF,YAAA,gBAAgB,GAAG,CAAnB;AACJ,mBAAA,CAAA;AAAA;AAAA,cAAM,cAAc,CAAC,GAAD,EAAM,gBAAN,EAAwB,KAAxB,EAA+B,UAAC,SAAD,EAAY,KAAZ,EAAiB;AAChE,kBAAM,WAAW,GAAG,IAAI,CAAC,GAAL,CAAS,KAAK,GAAG,gBAAjB,EAAmC,SAAnC,CAApB;AACA,cAAA,cAAc,CAAC,KAAD,EAAQ,WAAR,EAAqB,UAArB,CAAd;AACA,cAAA,gBAAgB,IAAI,WAApB;AACA,qBAAO,WAAP;AACH,aALmB,EAKjB,UAAC,GAAD,EAAM,KAAN,EAAW;AAAK,qBAAA,GAAG,CAAC,MAAJ,CAAW;AAAE,gBAAA,OAAO,EAAE,YAAX;AAAyB,gBAAA,OAAO,EAAE,KAAK,CAAC,QAAxC;AAAkD,gBAAA,GAAG,EAAhE;AAAW,eAAX,CAAA;AAA2E,aAL1E,CAApB,CAAA;;;AAAA,YAAA,EAAA,CAAA,IAAA;;AAOA,mBAAA,CAAA;AAAA;AAAA,cAAO,UAAP,CAAA;;;;AACH;;AAbqB,EAAA,SAAA,CAAA,cAAA,GAAc,cAAd;;AAetB,WAAgB,YAAhB,CAA6B,IAA7B,EAAyC;AACrC,QAAM,KAAK,GAAG,SAAS,CAAC,IAAD,CAAvB;AACA,QAAM,MAAM,GAAG,YAAY,CAAC,MAAb,CAAoB,KAAK,CAAC,IAA1B,EAAgC,IAAI,CAAC,GAAL,CAAS,IAAI,CAAC,MAAL,GAAc,EAAvB,EAA2B,CAA3B,CAAhC,CAAf;;AACA,WAAO,QAAQ,CAAC,KAAD,CAAf,EAAwB;AACpB,MAAA,YAAY,CAAC,GAAb,CAAiB,MAAjB,EAAyB,KAAK,CAAC,UAA/B,EAA2C,KAAK,CAAC,QAAjD;AACH;;AACD,WAAO,MAAP;AACH;;AAPe,EAAA,SAAA,CAAA,YAAA,GAAY,YAAZ;;AAShB,WAAS,qBAAT,CAA+B,KAA/B,EAAiD,KAAjD,EAAgE,MAAhE,EAA8E;AAC1E,QAAI,IAAI,GAAG,CAAX;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAApB,EAA2B,CAAC,EAA5B,EAAgC;AAC5B,UAAI,CAAC,QAAQ,CAAC,KAAD,CAAb,EAAsB,OAAO,IAAP;AACtB,MAAA,YAAY,CAAC,GAAb,CAAiB,MAAjB,EAAyB,KAAK,CAAC,UAA/B,EAA2C,KAAK,CAAC,QAAjD;AACA,MAAA,IAAI;AACP;;AACD,WAAO,IAAP;AACH;;AAED,WAAsB,iBAAtB,CAAwC,IAAxC,EAAsD,GAAtD,EAA2E,SAA3E,EAA6F;AAAlB,QAAA,SAAA,KAAA,KAAA,CAAA,EAAA;AAAA,MAAA,SAAA,GAAA,MAAA;AAAkB;;;;;;;AACnF,YAAA,KAAK,GAAG,SAAS,CAAC,IAAD,CAAjB;AACA,YAAA,MAAM,GAAG,YAAY,CAAC,MAAb,CAAoB,KAAK,CAAC,IAA1B,EAAgC,IAAI,CAAC,GAAL,CAAS,IAAI,CAAC,MAAL,GAAc,EAAvB,EAA2B,CAA3B,CAAhC,CAAT;AAEN,mBAAA,CAAA;AAAA;AAAA,cAAM,cAAc,CAAC,GAAD,EAAM,SAAN,EAAiB,KAAjB,EAAwB,UAAC,SAAD,EAAY,KAAZ,EAAiB;AACzD,cAAA,qBAAqB,CAAC,KAAD,EAAQ,SAAR,EAAmB,MAAnB,CAArB;AACA,qBAAO,KAAK,CAAC,QAAN,GAAiB,KAAK,CAAC,MAAvB,GAAgC,SAAhC,GAA4C,CAAnD;AACH,aAHmB,EAGjB,UAAC,GAAD,EAAM,KAAN,EAAW;AAAK,qBAAA,GAAG,CAAC,MAAJ,CAAW;AAAE,gBAAA,OAAO,EAAE,YAAX;AAAyB,gBAAA,OAAO,EAAE,KAAK,CAAC,QAAxC;AAAkD,gBAAA,GAAG,EAAhE;AAAW,eAAX,CAAA;AAA2E,aAH1E,CAApB,CAAA;;;AAAA,YAAA,EAAA,CAAA,IAAA;;AAKA,mBAAA,CAAA;AAAA;AAAA,cAAO,MAAP,CAAA;;;;AACH;;AAVqB,EAAA,SAAA,CAAA,iBAAA,GAAiB,iBAAjB;AAYtB;;AAEG;;AACH,WAAgB,QAAhB,CAAyB,KAAzB,EAAyC;AACrC,WAAO,KAAK,CAAC,QAAN,GAAiB,KAAK,CAAC,MAA9B,EAAsC;AAClC,cAAQ,KAAK,CAAC,IAAN,CAAW,UAAX,CAAsB,KAAK,CAAC,QAA5B,CAAR;AACI,aAAK,CAAL,CADJ,CACY;;AACR,aAAK,EAAL,CAFJ,CAEa;;AACT,aAAK,EAAL,CAHJ,CAGa;;AACT,aAAK,EAAL;AAAS;AACL,UAAA,KAAK,CAAC,QAAN,GAAiB,KAAK,CAAC,QAAvB;AACA;;AACJ;AACI,YAAE,KAAK,CAAC,QAAR;AACA;AATR;AAWH;;AACD,IAAA,KAAK,CAAC,QAAN,GAAiB,KAAK,CAAC,QAAvB;AACH;;AAfe,EAAA,SAAA,CAAA,QAAA,GAAQ,QAAR;AAiBhB;;;AAGG;;AACH,WAAgB,cAAhB,CAA+B,KAA/B,EAA+C;AAC3C,QAAI,IAAI,GAAG,CAAC,CAAZ;;AACA,WAAO,KAAK,CAAC,QAAN,GAAiB,KAAK,CAAC,MAA9B,EAAsC;AAClC,UAAM,CAAC,GAAG,KAAK,CAAC,IAAN,CAAW,UAAX,CAAsB,KAAK,CAAC,QAA5B,CAAV;;AACA,cAAQ,CAAR;AACI,aAAK,CAAL,CADJ,CACY;;AACR,aAAK,EAAL;AAAS;AACL,UAAA,IAAI,GAAG,CAAP;AACA,YAAE,KAAK,CAAC,QAAR;AACA;;AACJ,aAAK,EAAL;AAAS;AACL;AACA,cAAI,IAAI,KAAK,EAAb,EAAiB;AACb,cAAE,KAAK,CAAC,UAAR;AACH;;AACD,UAAA,IAAI,GAAG,CAAP;AACA,YAAE,KAAK,CAAC,QAAR;AACA;;AACJ,aAAK,EAAL;AAAS;AACL,UAAA,IAAI,GAAG,CAAP;AACA,YAAE,KAAK,CAAC,QAAR;AACA,YAAE,KAAK,CAAC,UAAR;AACA;;AACJ;AACI,iBAAO,IAAP;AApBR;AAsBH;;AACD,WAAO,IAAP;AACH;;AA5Be,EAAA,SAAA,CAAA,cAAA,GAAc,cAAd;AA8BhB;;AACA,WAAgB,IAAhB,CAAqB,KAArB,EAAuC,KAAvC,EAAsD,GAAtD,EAAiE;AACrD,QAAA,IAAI,GAAK,KAAK,CAAV,IAAJ;AACR,QAAI,CAAC,GAAG,KAAR;AAAA,QAAe,CAAC,GAAG,GAAG,GAAG,CAAzB;AAEA,QAAI,CAAC,GAAG,IAAI,CAAC,UAAL,CAAgB,CAAhB,CAAR;;AACA,WAAO,CAAC,CAAC,KAAK,CAAN,IAAW,CAAC,KAAK,EAAlB,KAAyB,CAAC,IAAI,CAArC,EAAwC,CAAC,GAAG,IAAI,CAAC,UAAL,CAAgB,EAAE,CAAlB,CAAJ;;AACxC,IAAA,CAAC,GAAG,IAAI,CAAC,UAAL,CAAgB,CAAhB,CAAJ;;AACA,WAAO,CAAC,CAAC,KAAK,CAAN,IAAW,CAAC,KAAK,EAAlB,KAAyB,CAAC,IAAI,CAArC,EAAwC,CAAC,GAAG,IAAI,CAAC,UAAL,CAAgB,EAAE,CAAlB,CAAJ;;AAExC,IAAA,KAAK,CAAC,UAAN,GAAmB,CAAnB;AACA,IAAA,KAAK,CAAC,QAAN,GAAiB,CAAC,GAAG,CAArB;AACA,IAAA,KAAK,CAAC,QAAN,GAAiB,GAAjB;AACA,WAAO,KAAP;AACH;;AAbe,EAAA,SAAA,CAAA,IAAA,GAAI,IAAJ;AAcnB,CAlND,EAAU,SAAS,KAAT,SAAS,GAAA,EAAA,CAAnB;;AAoNA,OAAM,SAAU,OAAV,CAAkB,IAAlB,EAAgC,KAAhC,EAA+C,GAA/C,EAA0D;AAC5D,MAAI,CAAC,GAAG,KAAR;AAAA,MAAe,CAAC,GAAG,GAAG,GAAG,CAAzB;AACA,MAAI,CAAC,GAAG,IAAI,CAAC,UAAL,CAAgB,CAAhB,CAAR;;AACA,SAAO,CAAC,CAAC,KAAK,CAAN,IAAW,CAAC,KAAK,EAAlB,KAAyB,CAAC,IAAI,CAArC,EAAwC,CAAC,GAAG,IAAI,CAAC,UAAL,CAAgB,EAAE,CAAlB,CAAJ;;AACxC,EAAA,CAAC,GAAG,IAAI,CAAC,UAAL,CAAgB,CAAhB,CAAJ;;AACA,SAAO,CAAC,CAAC,KAAK,CAAN,IAAW,CAAC,KAAK,EAAlB,KAAyB,CAAC,IAAI,CAArC,EAAwC,CAAC,GAAG,IAAI,CAAC,UAAL,CAAgB,EAAE,CAAlB,CAAJ;;AACxC,SAAO,IAAI,CAAC,SAAL,CAAe,CAAf,EAAkB,CAAC,GAAG,CAAtB,CAAP;AACH;AAED,OAAM,IAAW,YAAX;;AAAN,CAAA,UAAiB,YAAjB,EAA6B;AAOzB,WAAS,MAAT,CAAgB,OAAhB,EAAgC;AAC5B;AACA,QAAM,SAAS,GAAG,IAAI,WAAJ,CAAiB,OAAO,OAAO,CAAC,OAAR,CAAgB,MAAxB,GAAkC,CAAlD,CAAlB;AACA,IAAA,SAAS,CAAC,GAAV,CAAc,OAAO,CAAC,OAAtB;AACA,IAAA,OAAO,CAAC,OAAR,GAAkB,SAAlB;AACA,IAAA,OAAO,CAAC,gBAAR,GAA4B,SAAS,CAAC,MAAV,GAAmB,CAApB,GAAyB,CAApD;AACH;;AAED,WAAgB,GAAhB,CAAoB,MAApB,EAAoC,KAApC,EAAmD,GAAnD,EAA8D;AAC1D,QAAM,OAAO,GAAG,MAAhB;;AACA,QAAI,OAAO,CAAC,MAAR,GAAiB,OAAO,CAAC,gBAA7B,EAA+C;AAC3C,MAAA,MAAM,CAAC,OAAD,CAAN;AACH;;AACD,IAAA,OAAO,CAAC,OAAR,CAAgB,OAAO,CAAC,MAAR,EAAhB,IAAoC,KAApC;AACA,IAAA,OAAO,CAAC,OAAR,CAAgB,OAAO,CAAC,MAAR,EAAhB,IAAoC,GAApC;AACA,IAAA,MAAM,CAAC,KAAP;AACH;;AARe,EAAA,YAAA,CAAA,GAAA,GAAG,GAAH;;AAUhB,WAAgB,QAAhB,CAAyB,MAAzB,EAAyC,SAAzC,EAA6D;AACzD,IAAA,GAAG,CAAC,MAAD,EAAS,SAAS,CAAC,UAAnB,EAA+B,SAAS,CAAC,QAAzC,CAAH;AACH;;AAFe,EAAA,YAAA,CAAA,QAAA,GAAQ,QAAR;;AAIhB,WAAgB,YAAhB,CAA6B,MAA7B,EAA6C,KAA7C,EAA4D,GAA5D,EAAuE;AAClE,IAAA,MAAkB,CAAC,OAAnB,CAA4B,MAAkB,CAAC,MAAnB,EAA5B,IAA2D,KAA3D;AACA,IAAA,MAAkB,CAAC,OAAnB,CAA4B,MAAkB,CAAC,MAAnB,EAA5B,IAA2D,GAA3D;AACD,IAAA,MAAM,CAAC,KAAP;AACH;;AAJe,EAAA,YAAA,CAAA,YAAA,GAAY,YAAZ;;AAMhB,WAAgB,MAAhB,CAAuB,IAAvB,EAAqC,IAArC,EAAiD;AAC7C,IAAA,IAAI,GAAG,IAAI,CAAC,GAAL,CAAS,EAAT,EAAa,IAAb,CAAP;AACA,WAAgB;AACZ,MAAA,IAAI,EAAA,IADQ;AAEZ,MAAA,gBAAgB,EAAG,IAAI,GAAG,CAAR,GAAa,CAFnB;AAGZ,MAAA,KAAK,EAAE,CAHK;AAIZ,MAAA,MAAM,EAAE,CAJI;AAKZ,MAAA,OAAO,EAAE,IAAI,WAAJ,CAAgB,IAAhB;AALG,KAAhB;AAOH;;AATe,EAAA,YAAA,CAAA,MAAA,GAAM,MAAN;AAUnB,CA7CD,EAAiB,YAAY,KAAZ,YAAY,GAAA,EAAA,CAA7B","sourceRoot":"","sourcesContent":["/**\r\n * Copyright (c) 2017 mol* contributors, licensed under MIT, See LICENSE file for more info.\r\n *\r\n * mostly from https://github.com/dsehnal/CIFTools.js\r\n * @author David Sehnal <david.sehnal@gmail.com>\r\n * @author Alexander Rose <alexander.rose@weirdbyte.de>\r\n */\r\nimport { __awaiter, __generator } from \"tslib\";\r\nimport { chunkedSubtask } from '../../../../mol-task';\r\nexport { Tokenizer };\r\nfunction Tokenizer(data) {\r\n    return {\r\n        data: data,\r\n        position: 0,\r\n        length: data.length,\r\n        lineNumber: 1,\r\n        tokenStart: 0,\r\n        tokenEnd: 0\r\n    };\r\n}\r\n(function (Tokenizer) {\r\n    function getTokenString(state) {\r\n        return state.data.substring(state.tokenStart, state.tokenEnd);\r\n    }\r\n    Tokenizer.getTokenString = getTokenString;\r\n    /** Resets the state */\r\n    function reset(state) {\r\n        state.position = 0;\r\n        state.lineNumber = 1;\r\n        state.tokenStart = 0;\r\n        state.tokenEnd = 0;\r\n    }\r\n    Tokenizer.reset = reset;\r\n    /**\r\n     * Eat everything until a newline occurs.\r\n     */\r\n    function eatLine(state) {\r\n        var data = state.data;\r\n        while (state.position < state.length) {\r\n            switch (data.charCodeAt(state.position)) {\r\n                case 10: // \\n\r\n                    state.tokenEnd = state.position;\r\n                    ++state.position;\r\n                    ++state.lineNumber;\r\n                    return true;\r\n                case 13: // \\r\r\n                    state.tokenEnd = state.position;\r\n                    ++state.position;\r\n                    ++state.lineNumber;\r\n                    if (data.charCodeAt(state.position) === 10) {\r\n                        ++state.position;\r\n                    }\r\n                    return true;\r\n                default:\r\n                    ++state.position;\r\n                    break;\r\n            }\r\n        }\r\n        state.tokenEnd = state.position;\r\n        return state.tokenStart !== state.tokenEnd;\r\n    }\r\n    Tokenizer.eatLine = eatLine;\r\n    /** Sets the current token start to the current position */\r\n    function markStart(state) {\r\n        state.tokenStart = state.position;\r\n    }\r\n    Tokenizer.markStart = markStart;\r\n    /** Sets the current token start to current position and moves to the next line. */\r\n    function markLine(state) {\r\n        state.tokenStart = state.position;\r\n        return eatLine(state);\r\n    }\r\n    Tokenizer.markLine = markLine;\r\n    /** Advance the state and return line as string. */\r\n    function readLine(state) {\r\n        markLine(state);\r\n        return getTokenString(state);\r\n    }\r\n    Tokenizer.readLine = readLine;\r\n    /** Advance the state and return trimmed line as string. */\r\n    function readLineTrim(state) {\r\n        markLine(state);\r\n        var position = state.position;\r\n        trim(state, state.tokenStart, state.tokenEnd);\r\n        state.position = position;\r\n        return getTokenString(state);\r\n    }\r\n    Tokenizer.readLineTrim = readLineTrim;\r\n    function readLinesChunk(state, count, tokens) {\r\n        var read = 0;\r\n        for (var i = 0; i < count; i++) {\r\n            if (!markLine(state))\r\n                return read;\r\n            TokenBuilder.addUnchecked(tokens, state.tokenStart, state.tokenEnd);\r\n            read++;\r\n        }\r\n        return read;\r\n    }\r\n    /** Advance the state by the given number of lines and return them*/\r\n    function markLines(state, count) {\r\n        var lineTokens = TokenBuilder.create(state.data, count * 2);\r\n        readLinesChunk(state, count, lineTokens);\r\n        return lineTokens;\r\n    }\r\n    Tokenizer.markLines = markLines;\r\n    /** Advance the state by the given number of lines and return them */\r\n    function readLines(state, count) {\r\n        var ret = [];\r\n        for (var i = 0; i < count; i++) {\r\n            ret.push(Tokenizer.readLine(state));\r\n        }\r\n        return ret;\r\n    }\r\n    Tokenizer.readLines = readLines;\r\n    /** Advance the state by the given number of lines and return line starts/ends as tokens. */\r\n    function readLinesAsync(state, count, ctx, initialLineCount) {\r\n        if (initialLineCount === void 0) { initialLineCount = 100000; }\r\n        return __awaiter(this, void 0, void 0, function () {\r\n            var length, lineTokens, linesAlreadyRead;\r\n            return __generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0:\r\n                        length = state.length;\r\n                        lineTokens = TokenBuilder.create(state.data, count * 2);\r\n                        linesAlreadyRead = 0;\r\n                        return [4 /*yield*/, chunkedSubtask(ctx, initialLineCount, state, function (chunkSize, state) {\r\n                                var linesToRead = Math.min(count - linesAlreadyRead, chunkSize);\r\n                                readLinesChunk(state, linesToRead, lineTokens);\r\n                                linesAlreadyRead += linesToRead;\r\n                                return linesToRead;\r\n                            }, function (ctx, state) { return ctx.update({ message: 'Parsing...', current: state.position, max: length }); })];\r\n                    case 1:\r\n                        _a.sent();\r\n                        return [2 /*return*/, lineTokens];\r\n                }\r\n            });\r\n        });\r\n    }\r\n    Tokenizer.readLinesAsync = readLinesAsync;\r\n    function readAllLines(data) {\r\n        var state = Tokenizer(data);\r\n        var tokens = TokenBuilder.create(state.data, Math.max(data.length / 80, 2));\r\n        while (markLine(state)) {\r\n            TokenBuilder.add(tokens, state.tokenStart, state.tokenEnd);\r\n        }\r\n        return tokens;\r\n    }\r\n    Tokenizer.readAllLines = readAllLines;\r\n    function readLinesChunkChecked(state, count, tokens) {\r\n        var read = 0;\r\n        for (var i = 0; i < count; i++) {\r\n            if (!markLine(state))\r\n                return read;\r\n            TokenBuilder.add(tokens, state.tokenStart, state.tokenEnd);\r\n            read++;\r\n        }\r\n        return read;\r\n    }\r\n    function readAllLinesAsync(data, ctx, chunkSize) {\r\n        if (chunkSize === void 0) { chunkSize = 100000; }\r\n        return __awaiter(this, void 0, void 0, function () {\r\n            var state, tokens;\r\n            return __generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0:\r\n                        state = Tokenizer(data);\r\n                        tokens = TokenBuilder.create(state.data, Math.max(data.length / 80, 2));\r\n                        return [4 /*yield*/, chunkedSubtask(ctx, chunkSize, state, function (chunkSize, state) {\r\n                                readLinesChunkChecked(state, chunkSize, tokens);\r\n                                return state.position < state.length ? chunkSize : 0;\r\n                            }, function (ctx, state) { return ctx.update({ message: 'Parsing...', current: state.position, max: length }); })];\r\n                    case 1:\r\n                        _a.sent();\r\n                        return [2 /*return*/, tokens];\r\n                }\r\n            });\r\n        });\r\n    }\r\n    Tokenizer.readAllLinesAsync = readAllLinesAsync;\r\n    /**\r\n     * Eat everything until a whitespace/newline occurs.\r\n     */\r\n    function eatValue(state) {\r\n        while (state.position < state.length) {\r\n            switch (state.data.charCodeAt(state.position)) {\r\n                case 9: // \\t\r\n                case 10: // \\n\r\n                case 13: // \\r\r\n                case 32: // ' '\r\n                    state.tokenEnd = state.position;\r\n                    return;\r\n                default:\r\n                    ++state.position;\r\n                    break;\r\n            }\r\n        }\r\n        state.tokenEnd = state.position;\r\n    }\r\n    Tokenizer.eatValue = eatValue;\r\n    /**\r\n     * Skips all the whitespace - space, tab, newline, CR\r\n     * Handles incrementing line count.\r\n     */\r\n    function skipWhitespace(state) {\r\n        var prev = -1;\r\n        while (state.position < state.length) {\r\n            var c = state.data.charCodeAt(state.position);\r\n            switch (c) {\r\n                case 9: // '\\t'\r\n                case 32: // ' '\r\n                    prev = c;\r\n                    ++state.position;\r\n                    break;\r\n                case 10: // \\n\r\n                    // handle \\r\\n\r\n                    if (prev !== 13) {\r\n                        ++state.lineNumber;\r\n                    }\r\n                    prev = c;\r\n                    ++state.position;\r\n                    break;\r\n                case 13: // \\r\r\n                    prev = c;\r\n                    ++state.position;\r\n                    ++state.lineNumber;\r\n                    break;\r\n                default:\r\n                    return prev;\r\n            }\r\n        }\r\n        return prev;\r\n    }\r\n    Tokenizer.skipWhitespace = skipWhitespace;\r\n    /** Trims spaces and tabs */\r\n    function trim(state, start, end) {\r\n        var data = state.data;\r\n        var s = start, e = end - 1;\r\n        var c = data.charCodeAt(s);\r\n        while ((c === 9 || c === 32) && s <= e)\r\n            c = data.charCodeAt(++s);\r\n        c = data.charCodeAt(e);\r\n        while ((c === 9 || c === 32) && e >= s)\r\n            c = data.charCodeAt(--e);\r\n        state.tokenStart = s;\r\n        state.tokenEnd = e + 1;\r\n        state.position = end;\r\n        return state;\r\n    }\r\n    Tokenizer.trim = trim;\r\n})(Tokenizer || (Tokenizer = {}));\r\nexport function trimStr(data, start, end) {\r\n    var s = start, e = end - 1;\r\n    var c = data.charCodeAt(s);\r\n    while ((c === 9 || c === 32) && s <= e)\r\n        c = data.charCodeAt(++s);\r\n    c = data.charCodeAt(e);\r\n    while ((c === 9 || c === 32) && e >= s)\r\n        c = data.charCodeAt(--e);\r\n    return data.substring(s, e + 1);\r\n}\r\nexport var TokenBuilder;\r\n(function (TokenBuilder) {\r\n    function resize(builder) {\r\n        // scale the size using golden ratio, because why not.\r\n        var newBuffer = new Uint32Array((1.61 * builder.indices.length) | 0);\r\n        newBuffer.set(builder.indices);\r\n        builder.indices = newBuffer;\r\n        builder.indicesLenMinus2 = (newBuffer.length - 2) | 0;\r\n    }\r\n    function add(tokens, start, end) {\r\n        var builder = tokens;\r\n        if (builder.offset > builder.indicesLenMinus2) {\r\n            resize(builder);\r\n        }\r\n        builder.indices[builder.offset++] = start;\r\n        builder.indices[builder.offset++] = end;\r\n        tokens.count++;\r\n    }\r\n    TokenBuilder.add = add;\r\n    function addToken(tokens, tokenizer) {\r\n        add(tokens, tokenizer.tokenStart, tokenizer.tokenEnd);\r\n    }\r\n    TokenBuilder.addToken = addToken;\r\n    function addUnchecked(tokens, start, end) {\r\n        tokens.indices[tokens.offset++] = start;\r\n        tokens.indices[tokens.offset++] = end;\r\n        tokens.count++;\r\n    }\r\n    TokenBuilder.addUnchecked = addUnchecked;\r\n    function create(data, size) {\r\n        size = Math.max(10, size);\r\n        return {\r\n            data: data,\r\n            indicesLenMinus2: (size - 2) | 0,\r\n            count: 0,\r\n            offset: 0,\r\n            indices: new Uint32Array(size)\r\n        };\r\n    }\r\n    TokenBuilder.create = create;\r\n})(TokenBuilder || (TokenBuilder = {}));\r\n//# sourceMappingURL=tokenizer.js.map"]},"metadata":{},"sourceType":"module"}